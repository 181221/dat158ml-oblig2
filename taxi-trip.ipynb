{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Trip Duration\n",
    "1. Frame the problem and look at the big picture\n",
    "2. Get the data\n",
    "3. Explore the data to gain insights\n",
    "4. Prepare the data to better expose the underlying data patterns to machine learning algorithms\n",
    "5. Explore many different models and short-list the best ones\n",
    "6. Fine-tune your models and combine them into a great solution\n",
    "7. Present your solution\n",
    "8. Launch, monitor and maintain your system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame the problem and look at the big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is based on the 2016 NYC Yellow Cab trip record data made available in Big Query on Google Cloud Platform. The data was originally published by the NYC Taxi and Limousine Commission (TLC). The data was sampled and cleaned for the purposes of this playground competition. \n",
    "In this project the goal is to make a model based on individual trip attributes, to be able to predict the duration of each trip in the test set.\n",
    "\n",
    "[New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The initial data from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data description has following columns:\n",
    "\n",
    "* **id** - a unique identifier for each trip\n",
    "* **vendor_id** - a code indicating the provider associated with the trip record\n",
    "* **pickup_datetime** - date and time when the meter was engaged\n",
    "* **dropoff_datetime** - date and time when the meter was disengaged\n",
    "* **passenger_count** - the number of passengers in the vehicle (driver entered value)\n",
    "* **pickup_longitude** - the longitude where the meter was engaged\n",
    "* **pickup_latitude** - the latitude where the meter was engaged\n",
    "* **dropoff_longitude** - the longitude where the meter was disengaged\n",
    "* **dropoff_latitude** - the latitude where the meter was disengaged\n",
    "* **store_and_fwd_flag** - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server (Y=store and   forward; N=not a store and forward trip)\n",
    "* **trip_duration** - duration of the trip in second\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import The Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^RuntimeWarning\")\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "TAXI_PATH = os.path.join(\"data\", \"taxi\")\n",
    "\n",
    "def load_taxi_data(taxi_path=TAXI_PATH):\n",
    "    csv_path = os.path.join(taxi_path, \"train.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_taxi_data()\n",
    "csv_path = os.path.join(TAXI_PATH, \"test.csv\")\n",
    "test = pd.read_csv(csv_path)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising The Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickups and dropoffs of trips in New York City with a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.loc[(train.pickup_latitude > 40.6) & (train.pickup_latitude < 40.9)]\n",
    "df = df.loc[(df.dropoff_latitude>40.6) & (df.dropoff_latitude < 40.9)]\n",
    "df = df.loc[(df.dropoff_longitude > -74.05) & (df.dropoff_longitude < -73.7)]\n",
    "df = df.loc[(df.pickup_longitude > -74.05) & (df.pickup_longitude < -73.7)]\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(15,10))\n",
    "\n",
    "df.plot(kind='scatter', x='pickup_longitude', y='pickup_latitude',\n",
    "                color='red', \n",
    "                s=.02, alpha=.6, subplots=True, ax=ax1)\n",
    "ax1.set_title(\"Pickups\")\n",
    "ax1.set_facecolor('black')\n",
    "\n",
    "df.plot(kind='scatter', x='dropoff_longitude', y='dropoff_latitude',\n",
    "                color='red', \n",
    "                s=.02, alpha=.6, subplots=True, ax=ax2)\n",
    "ax2.set_title(\"Dropoffs\")\n",
    "ax2.set_facecolor('black') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can se in the above map - most of the journeys have been from and to manhattan.\n",
    "There are two airports, John F. Kennedy and LA Guardia Airport in queens which has a good amount of taxi trips from and too. \n",
    "When calculating the euclidean distance the distance will be hugely afftected by the taxi trips that start in manhattan and ends outside manhattan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the pickups and dropoffs of trips in folium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium \n",
    "\n",
    "newyork_map = folium.Map(location=[40.767937,-73.982155 ], tiles='OpenStreetMap', zoom_start=12)\n",
    "\n",
    "def createMap(geo_map, data, i=100):\n",
    "    for each in train[:i].iterrows():\n",
    "        p1 = [each[1]['pickup_latitude'] ,each[1]['pickup_longitude']]\n",
    "        p2 = [each[1]['dropoff_latitude'], each[1]['dropoff_longitude']]\n",
    "        folium.CircleMarker(p1,\n",
    "                            radius=3,\n",
    "                            color='blue',\n",
    "                            popup=str(each[1]['pickup_latitude'])+','+str(each[1]['pickup_longitude']),\n",
    "                            fill_color='#FD8A6C'\n",
    "                            ).add_to(geo_map)\n",
    "        folium.CircleMarker(p2,\n",
    "                            radius=3,\n",
    "                            color='red',\n",
    "                            popup=str(each[1]['dropoff_latitude'])+','+str(each[1]['dropoff_longitude']),\n",
    "                            fill_color='#FD8A6C'\n",
    "                            ).add_to(geo_map)\n",
    "        folium.PolyLine(locations=[p1, p2], color='green').add_to(geo_map)\n",
    "    \n",
    "createMap(newyork_map, train)\n",
    "\n",
    "newyork_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alot of the taxi-trips starts and ends in manhattan. Lets find out how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manh_checker(x):\n",
    "    return 40.7091 < x['dropoff_latitude'] < 40.8205 and \\\n",
    "    -74.0096 < x['dropoff_longitude'] < -73.9307 and \\\n",
    "    40.7091 < x['pickup_latitude'] < 40.8205 and \\\n",
    "    -74.0096 < x['pickup_longitude'] < -73.9307\n",
    "   \n",
    "#test = train.apply(manh_checker, axis = 1) \n",
    "#print(test.sum()*100 / len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 80% of all journeys start and end in (or slighlty around) Manhattan island. The manhattan distance can give a better estimate of the distance. We will come back to that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There is an outlier where the passenger count is 0. We need to remove that.\n",
    "2. There is also a minimum trip duration of 1 second, those trips are going nowhere and the maximum is 35,26,282 seconds.\n",
    "There is some outliers here which I will remove later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.isnull().sum(axis=0).sum(axis=0))\n",
    "print(train.isnull().sum(axis=0).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values which is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#durations_longer_than_4timer = train.query(\"trip_duration > 10800\").groupby([\"trip_duration\"]).size()\n",
    "#long_durations = pd.DataFrame({'id'}:durations_longer_than_4timer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trip duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train.trip_duration,train.index,color=\"lightblue\")\n",
    "plt.xlabel(\"Trip Duration\")\n",
    "plt.title(\"Trip Duration for each Taxi ride\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some trips are going too far away from New York city(Long rides who knows). These are outliers. Since the evaluation metrics is RMSLE(Root Mean Squared Logarithmic Error), we can log transform trip duration and use RMSE(Root Mean Squared Error) for training.\n",
    "The graph is skewed to the right. From this graph I cannot tell where the mean is. The graph does not explain the data well. We can do a log transform to have a better look. The log transformation will make highly skewed distributions less skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_trip_duration'] = np.log1p(train['trip_duration'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(12,8))\n",
    "fig.suptitle('Train trip duration and log of trip duration')\n",
    "ax1.set_ylabel('count')\n",
    "ax1.set_xlabel('trip duration')\n",
    "ax2.set_xlabel('log(trip duration)')\n",
    "ax1.hist(train.trip_duration,bins=7, color=\"goldenrod\")\n",
    "ax2.hist(train.log_trip_duration,bins=100, color=\"lightblue\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go, now its better. Lets have a look at the skewness and kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % train['log_trip_duration'].skew())\n",
    "print(\"Kurtosis: %f\" % train['log_trip_duration'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Skewness is a measure of symmetry, or more precisely, the lack of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\n",
    "2. Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. That is, data sets with high kurtosis tend to have heavy tails, or outliers. Data sets with low kurtosis tend to have light tails, or lack of outliers. A uniform distribution would be the extreme case. \n",
    "\n",
    "From what we can see in the histogram to the left there are some points that falls outside the bellcurve. These are the outliers I mentioned earlier. These taxi trips have a really long trip duration. But it doesnt necessarily mean that they are outliers and should be removed. Because it could be trips where they are stuck in really bad traffic. On for example hollydays the traffic can be huge, not to mention black friday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From earlier we found out that the maximum trip duration was about 100 hours. Lets have a closer look to find out wether there are more outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(1, 1, figsize=(11, 7), sharex=True)\n",
    "sns.despine(left=True)\n",
    "sns.distplot(np.log(train['trip_duration'].values+1), axlabel = 'Log(trip_duration)', label = 'log(trip_duration)', bins = 50, color=\"r\")\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few trips that are very large and are more than 3 standard deviations away from the mean. These can be far away from new york. Lets have a close look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(2,2,figsize=(10, 10), sharex=False, sharey = False)\n",
    "sns.despine(left=True)\n",
    "sns.distplot(train['pickup_latitude'].values, label = 'pickup_latitude',color=\"m\",bins = 100, ax=axes[0,0])\n",
    "sns.distplot(train['pickup_longitude'].values, label = 'pickup_longitude',color=\"m\",bins =100, ax=axes[0,1])\n",
    "sns.distplot(train['dropoff_latitude'].values, label = 'dropoff_latitude',color=\"m\",bins =100, ax=axes[1, 0])\n",
    "sns.distplot(train['dropoff_longitude'].values, label = 'dropoff_longitude',color=\"m\",bins =100, ax=axes[1, 1])\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.tight_layout()\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pick and drop latidude are centered around 40 to 41, and longitude are around -74, -73\n",
    "the sns is getting affected by the outliers. Trips that are far away have affected this plot. As we can see there are location from 32 tp 44 and -120 to -60. These are affecting the model and will not give us a better estimate on trips in New York. The data is not well descibed by the normal distrubtion.\n",
    "If we contrain the locations to only be in New York City we can get a better understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df = train.loc[(train.pickup_latitude > 40.6) & (train.pickup_latitude < 40.9)]\n",
    "df = df.loc[(df.dropoff_latitude>40.6) & (df.dropoff_latitude < 40.9)]\n",
    "df = df.loc[(df.dropoff_longitude > -74.05) & (df.dropoff_longitude < -73.7)]\n",
    "df = df.loc[(df.pickup_longitude > -74.05) & (df.pickup_longitude < -73.7)]\n",
    "train_data_new = df.copy()\n",
    "\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(2,2,figsize=(12, 12), sharex=False, sharey = False)#\n",
    "sns.despine(left=True)\n",
    "sns.distplot(train_data_new['pickup_latitude'].values, label = 'pickup_latitude',color=\"m\",bins = 100, ax=axes[0,0])\n",
    "sns.distplot(train_data_new['pickup_longitude'].values, label = 'pickup_longitude',color=\"g\",bins =100, ax=axes[0,1])\n",
    "sns.distplot(train_data_new['dropoff_latitude'].values, label = 'dropoff_latitude',color=\"m\",bins =100, ax=axes[1, 0])\n",
    "sns.distplot(train_data_new['dropoff_longitude'].values, label = 'dropoff_longitude',color=\"g\",bins =100, ax=axes[1, 1])\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.tight_layout()\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))\n",
    "print(df.shape[0], train.shape[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. latitude should be between 40.6 to 40.9\n",
    "2. Longitude should be between -74.05 to -73.70\n",
    "We can see that most of the trips are getting concentrated between these lat-long only. \n",
    "The trips that are far away from newyork should not be in the dataset since we are focusing on trip duration in  New York City. \n",
    "Removing these will give as a better model prediction. \n",
    "\n",
    "Notice that location around -73.90 and 40.65 is the location of the John F. Kennedy Airport and -74 which is manhattan where 80% of the trips accoured. This is good. This graph have a better explanation of the population(taxi trips).\n",
    "By removing the trips outside New York city the model becomes a better estimator of the mew.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets have a look at the two different vendors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"vendor_id\"].value_counts().plot(kind='bar',color=[\"goldenrod\",\"lightblue\"])\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.title(\"Vendors\")\n",
    "plt.ylabel(\"Count for each Vender\")\n",
    "plt.xlabel(\"Vendor Ids\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 Vendors are there, they can be representing 2 taxi companies. Vendor 2 has more share in taxi rides in New York city. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many passengers are traveling together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"passenger_count\"].value_counts().plot(kind='bar',color=[\"goldenrod\",\"lightblue\"])\n",
    "plt.title(\"Passengers in a group of\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.ylabel(\"Count for each passenger\")\n",
    "plt.xlabel(\"Number of Passengers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most popular choice of travel is single.\n",
    "2nd popular way of ride is with a single friend.\n",
    "May be for long cars popular choice of travel is in group of 5 and then in group of 6 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('passenger_count').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('passenger_count').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliners here. We have 53 and 23 trips with zero passengers. There is also two trips with 9 passengers. \n",
    "Other than that the data seems to match relatively between the two data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passenger count vs trip_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = train.groupby('passenger_count')['trip_duration'].mean()\n",
    "plt.subplots(1,1,figsize=(17,10))\n",
    "plt.ylim(ymin=0)\n",
    "plt.ylim(ymax=1100)\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('Time in Seconds')\n",
    "sns.barplot(pc.index,pc.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time goes slightly up with the number of passenger increasing but nothing significant. Which is interesting because the more passengers the more stops. Unless they are all going to the same place. Which in this set it seems that they do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whether the Trip Details are Stored Or Forwarded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"store_and_fwd_flag\"].value_counts().plot(kind='bar', color=[\"goldenrod\",\"lightblue\"])\n",
    "plt.title(\"Store and Forward cases\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.ylabel(\"Count for flags\")\n",
    "plt.xlabel(\"Flag\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all the journey details were immediately sent to vendors. Very few stored in device memory may be due to bad signal or bad weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract lot of insights from dates and time data we have.\n",
    "\n",
    "1. Pickup hour rushes can define start of office timings and drop offs in evening can tell till what time New Yorkers work.\n",
    "2. Weekdays and weekends can show another angle of city life. Weekends people will be getting up late and starting day late compared to weekdays. Also parties can go beyond midnight hours on weekends.\n",
    "3. We can also look out for some kind of seasonality. For example, during winter seasons traffic will be going slow due to snowfalls or wetness on Roads. So, trip Duration will be longer in winters than other seasons.\n",
    "4. Finding out wether it is a holiday or for example if it is black friday that will have an inpact on the trip duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping zero trip duration and passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.passenger_count != 0]\n",
    "test = test[test.passenger_count != 0]\n",
    "test = test[test.passenger_count != 9]\n",
    "train = train[train.trip_duration != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Extraction\n",
    "Extraction out the date time to multiple variables enables us to do one hot encoding. Ml models understands 0's and 1's istead of januar and februar\n",
    "Also by doing this we can get a better understanding of for example a given hour if it is rush or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range(start='2016-01-01', end='2016-12-31')\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dr.min(), end=dr.max())\n",
    "\n",
    "train['pickup_datetime']             = pd.to_datetime(train.pickup_datetime)\n",
    "train['holiday']                     = train['pickup_datetime'].isin(holidays)\n",
    "train['dropoff_datetime']            = pd.to_datetime(train.dropoff_datetime) # Not in Test\n",
    "\n",
    "train['pickup_weekday']              = pd.to_datetime(train.pickup_datetime).dt.dayofweek.astype('uint8')\n",
    "train['pickup_day']                  = pd.to_datetime(train.pickup_datetime).dt.day.astype('uint8')\n",
    "train['pickup_hour']                 = pd.to_datetime(train.pickup_datetime).dt.hour.astype('uint8')\n",
    "train['pickup_minute']               = pd.to_datetime(train.pickup_datetime).dt.minute.astype('uint8')\n",
    "train['pickup_second']               = pd.to_datetime(train.pickup_datetime).dt.second.astype('uint8')\n",
    "train[\"pickup_dayofyear\"]            = pd.to_datetime(train.pickup_datetime).dt.dayofyear.astype('uint8')\n",
    "train['pickup_month']                = pd.to_datetime(train.pickup_datetime).dt.month.astype('uint8')\n",
    "\n",
    "train['pickup_dt']                   = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "train['pickup_week_hour']            = train['pickup_weekday'] * 24 + train['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pickup_datetime']              = pd.to_datetime(test.pickup_datetime)\n",
    "test['holiday']                      = test['pickup_datetime'].isin(holidays)\n",
    "test['pickup_weekday']               = pd.to_datetime(test.pickup_datetime).dt.dayofweek.astype('uint8')\n",
    "test['pickup_day']                   = pd.to_datetime(test.pickup_datetime).dt.day.astype('uint8')\n",
    "test['pickup_hour']                  = pd.to_datetime(test.pickup_datetime).dt.hour.astype('uint8')\n",
    "test['pickup_minute']                = pd.to_datetime(test.pickup_datetime).dt.minute.astype('uint8')\n",
    "test['pickup_second']                = pd.to_datetime(test.pickup_datetime).dt.second.astype('uint8')\n",
    "test[\"pickup_dayofyear\"]             = pd.to_datetime(test.pickup_datetime).dt.dayofyear.astype('uint8')\n",
    "test['pickup_month']                 = pd.to_datetime(test.pickup_datetime).dt.month.astype('uint8')\n",
    "\n",
    "test['pickup_dt']                    = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "test['pickup_week_hour']             = test['pickup_weekday'] * 24 + test['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting holiday to 0 or 1\n",
    "train['holiday'] = 1 * (train.store_and_fwd_flag.values == False)\n",
    "test['holiday'] = 1 * (test.store_and_fwd_flag.values == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the dates has been extracted. Lets have a look at them on the graphs - Visualising The Dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6)) \n",
    "train.pickup_month.value_counts().plot(kind='bar',color=[\"goldenrod\",\"lightblue\"],align='center',width=0.2)\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.xlabel(\"months\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.title(\"Total trips in each month\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data from January to June of 2016. Highest number of trips happened in March and lowest in January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month and Trip Durations Together with Vendor Contribution\n",
    "Since we have kernel memory limit , I have taken subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(train.pickup_month[:1000],train.log_trip_duration[:1000],hue=train.vendor_id[:1000],palette={1:'r',2:'b'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vendors contribution is apporoximately same. \n",
    "1. There is linear relationship between Month and Trip Duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total trips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6)) \n",
    "train.pickup_day.value_counts().plot(kind='bar',color=[\"goldenrod\",\"lightblue\"],align='center',width=0.3)\n",
    "plt.xlabel(\"Days\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.title(\"Total trips on each day\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Highest number of trips happened on 16th of the month while lowest on 31st.\n",
    "2. 30th and 31st have less trips because we have 6 months data and 30th and 31st came only 3 times each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6)) \n",
    "train['pickup_datetime'].dt.weekday_name.value_counts().plot(kind='bar',color=[\"goldenrod\",\"lightblue\"],align='center',width=0.3)\n",
    "plt.xlabel(\"WeekDays\")\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.title(\"Total trips on each weekday\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest number of trips took place on every Friday of the week while lowest on Mondays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the average time taken by two different vendors vs weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "summary_wdays_avg_duration = pd.DataFrame(train.groupby(['vendor_id','pickup_weekday'])['trip_duration'].mean())\n",
    "summary_wdays_avg_duration.reset_index(inplace = True)\n",
    "summary_wdays_avg_duration['unit']=1\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=False, rc={'figure.figsize':(13.7,8.27)})\n",
    "sns.tsplot(data=summary_wdays_avg_duration, time=\"pickup_weekday\", unit = \"unit\", condition=\"vendor_id\", value=\"trip_duration\")\n",
    "sns.despine(bottom = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's clear that the vendor 1 is taking more time than vendor 2 on all the days of the week. The difference between the average time taken by vendor 1 is ~250 seconds more than vendor 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxi Trips By Dropoff Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6)) \n",
    "train['dropoff_datetime'].dt.hour.value_counts().plot(kind='bar',color=[\"goldenrod\",\"lightblue\"],align='center',width=0.3)\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.title(\"Total dropoffs at each hour\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest number of dropoffs were at 19:00 and the lowest were at 05:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_hour_duration = pd.DataFrame(train.groupby(['pickup_weekday','pickup_hour'])['trip_duration'].mean())\n",
    "summary_hour_duration.reset_index(inplace = True)\n",
    "summary_hour_duration['unit']=1\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=False, rc={'figure.figsize':(13.7,8.27)})\n",
    "sns.tsplot(data=summary_hour_duration, time=\"pickup_hour\", unit = \"unit\", condition=\"pickup_weekday\", value=\"trip_duration\")\n",
    "sns.despine(bottom = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On Sunday (0) and day Saturday (6), the trip duration is less that all the weekdays at 5 AM to 15 AM time.\n",
    "* See this, on Saturday around midnight, the taxi trips are taking far more than usual time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Convert store and forward flag to 0 or 1 so the algorithms can understand them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "test['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Distance and Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculations of the distances takes some time. So I have moved the calculation to create_distance_csv.ipynb. I have calculated the manhattan, euclidean and haversine distance. I have added their logarithms as well. Now lets import them and merge them with our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXI_PATH = os.path.join(\"data\", \"taxi\")\n",
    "csv_path = os.path.join(TAXI_PATH, \"train_distance.csv\")\n",
    "train_distance = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "csv_path = os.path.join(TAXI_PATH, \"test_distance.csv\")\n",
    "test_distance = pd.read_csv(csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(train_distance.set_index('id'), on='id')\n",
    "test = test.join(test_distance.set_index('id'), on='id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fastest route. OSRM\n",
    "I wanted to download the distances between the locations from google. But I have 1.4 millions of entries and I dont think google would like a api call like that. So I found another way to do it. There is an opensource algorithm - Open Source Routing Machine that can do it for me for free. There is already a csv on the internet which has an estimate of the total distance on this dataset.\n",
    "Which I am thankfull for. This will make a better estimate of the distance than manhattan and haversine - distance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXI_PATH = os.path.join(\"data\", \"taxi\")\n",
    "csv_path_part1 = os.path.join(TAXI_PATH, \"fastest_routes_train_part_1.csv\")\n",
    "csv_path_part2 = os.path.join(TAXI_PATH, \"fastest_routes_train_part_2.csv\")\n",
    "csv_path_test = os.path.join(TAXI_PATH, \"fastest_routes_test.csv\")\n",
    "cols = ['id', 'total_distance', 'total_travel_time',  'number_of_steps']\n",
    "\n",
    "fastest_routes1 = pd.read_csv(csv_path_part1, usecols = cols)\n",
    "fastest_routes2 = pd.read_csv(csv_path_part2, usecols = cols)\n",
    "test_fastest_routes = pd.read_csv(csv_path_test, usecols = cols)\n",
    "\n",
    "train_fastest_routes = pd.concat((fastest_routes1, fastest_routes2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fastest_routes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **number_of_steps** is the route steps for each route - which means how many right and left turns\n",
    "* **total_distance** - The shortest distance between to points. It does not depend on other variables. For example traffic data. Assuming the taxi drivers knows the shortest paths around the city. But there is always a chance that the driver takes a longer path.\n",
    "* **total_travel_time** - estimates the total travel time based on distance and speed. \n",
    "* **id** - id for the taxi to match the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets merge the new data into our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_fastest_routes, how='left', on='id')\n",
    "test = test.merge(test_fastest_routes, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'avg_speed_h'] = 1000 * train['haversine_distance'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_m'] = 1000 * train['manhattan_distance'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_eu'] = 1000 * train['euclidean_distance'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_osrm'] = train['total_distance'] / train['trip_duration']\n",
    "\n",
    "test.loc[:, 'avg_speed_h'] = 1000 * test['haversine_distance'] / train['trip_duration']\n",
    "test.loc[:, 'avg_speed_m'] = 1000 * test['manhattan_distance'] / train['trip_duration']\n",
    "test.loc[:, 'avg_speed_eu'] = 1000 * test['euclidean_distance'] / train['trip_duration']\n",
    "test.loc[:, 'avg_speed_osrm'] = test['total_distance'] / train['trip_duration']\n",
    "print(train.isnull().sum(axis=0).sum(axis=0))\n",
    "print(test.isnull().sum(axis=0).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, sharey=True)\n",
    "ax[0].plot(train.groupby('pickup_hour').mean()['avg_speed_h'], 'bo-', lw=2, alpha=0.7)\n",
    "ax[1].plot(train.groupby('pickup_weekday').mean()['avg_speed_h'], 'go-', lw=2, alpha=0.7)\n",
    "ax[2].plot(train.groupby('pickup_month').mean()['avg_speed_h'], 'ro-', lw=2, alpha=0.7)\n",
    "ax[0].set_xlabel('Hour of Day')\n",
    "ax[1].set_xlabel('Day of Week')\n",
    "ax[2].set_xlabel('Month of Year')\n",
    "ax[0].set_ylabel('Average Speed')\n",
    "fig.suptitle('Average Traffic Speed by Date-part')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most of the travelling in the Big Apple happens during work hours. \n",
    "* The average speed by weekday follows an expected trend. \n",
    "* Over the weekend (Friday, Saturday, Sunday) the average speed picks up quite nicely, indicating less traffic.\n",
    "* The winter months there are less trips indicating less traffic in general in the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average speed for regions in New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 3)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 3)\n",
    "gby_cols = ['pickup_lat_bin', 'pickup_long_bin']\n",
    "coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "coord_stats = coord_stats[coord_stats['id'] > 100]\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1)\n",
    "ax.scatter(train.pickup_longitude.values[:500000], train.pickup_latitude.values[:500000], color='black', s=1, alpha=0.5)\n",
    "ax.scatter(coord_stats.pickup_long_bin.values, coord_stats.pickup_lat_bin.values, c=coord_stats.avg_speed_h.values,\n",
    "           cmap='RdYlGn', s=20, alpha=0.5, vmin=1, vmax=8)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.title('Average speed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plot we can se that in manhattan there is more traffic indicating a lower average speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot(x='manhattan_distance', y='total_distance', style='o')  \n",
    "plt.title('manhattan vs total_distance')  \n",
    "plt.xlabel('Manhattan distance')  \n",
    "plt.ylabel('Total distance')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train.sample(n=round(0.10*len(train.index))) # 10 % of the training data.\n",
    "target = train_samples.log_trip_duration.values\n",
    "train_samples = train_samples.drop(['id', 'pickup_datetime', 'haversine_distance', 'manhattan_distance','euclidean_distance','avg_speed_h','avg_speed_m','avg_speed_eu','dropoff_datetime', 'trip_duration','log_trip_duration','pickup_dt'], axis=1)\n",
    "train_samples.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = test.sample(n=round(0.10*len(test.index))) # 10 % of the training data.\n",
    "Id=test.id.values\n",
    "test_samples = test_samples.drop(['id','pickup_datetime','pickup_dt','haversine_distance', 'manhattan_distance','euclidean_distance','avg_speed_h','avg_speed_m','avg_speed_eu'], axis=1)\n",
    "test.fillna(0,inplace=True)\n",
    "predictors=test_samples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(train_samples.columns)\n",
    "print(\"Difference of features in train and test are {}\".format(np.setdiff1d(test_samples.columns, train_samples.columns)))\n",
    "print(\"\")\n",
    "do_not_use_for_training = ['id', 'pickup_datetime', 'haversine_distance', 'manhattan_distance','euclidean_distance','avg_speed_h','avg_speed_m','avg_speed_eu','dropoff_datetime', 'trip_duration','log_trip_duration','pickup_dt']\n",
    "feature_names = [f for f in test_samples.columns if f not in do_not_use_for_training]\n",
    "print(\"We will be using following features for training {}.\".format(feature_names))\n",
    "print(\"\")\n",
    "print(\"Total number of features are {}.\".format(len(feature_names)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### splitting to train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_samples, target, random_state=42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestRegressor(n_estimators=100, max_depth=30, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(10): \n",
    "    print(f'{X_train.columns[indices[f]]}: {np.round(importances[indices[f]],2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=train_samples.columns\n",
    "importances=rf_clf.feature_importances_\n",
    "std = np.std([rf_clf.feature_importances_ for tree in rf_clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_important_features=[]\n",
    "for i in indices:\n",
    "    sorted_important_features.append(predictors[i])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature Importances By Random Forest Model\")\n",
    "plt.barh(range(len(indices)), importances[indices],\n",
    "       color=[\"goldenrod\",\"lightblue\"], yerr=std[indices], align=\"center\")\n",
    "plt.yticks(range(len(indices)), sorted_important_features, rotation='horizontal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse = False)), (\"xgb_model\", xgb.XGBRegressor())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_score(pred, true):\n",
    "    return (np.sum((np.log(1 + pred) - np.log(1 + true))**2) / len(pred))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmsle_score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmsle_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 80, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 25,\n",
    "            'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "\n",
    "# You could try to train with more epoch\n",
    "model = xgb.train(xgb_pars, dtrain, 20, watchlist, early_stopping_rounds=5,\n",
    "                  maximize=False, verbose_eval=1)\n",
    "\n",
    "\n",
    "print('Modeling RMSLE %.5f' % model.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling min_child_weight max_depth and number of steps gives a slightly better score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a better model - Thoughs\n",
    "To get a better prediction on the validation set. We can do some more feature engineering. Like importing the weather data to find out what kind of impact the weather has on the data. It would have been very good to find more information about the traffic - the pulse of the city. To know if a road is close or a bridge or if there has been a collision/accident.\n",
    "1. Cluster the neighborhoods can be tested to see if it has an impact on the model.\n",
    "2. Limit the dataset to only taxitrips within manhattan to see how well the model would have predicted taxi trips in manhattan. \n",
    "    * It would be interesting to lower the domain to see how much better the model would have done. Ofcourse it will be bad to send in the test data with a model that is based on manhattan. But for curiosity reasons it would be fun.\n",
    "\n",
    "I have downloaded a dataset from 2016 which I was going to implement but I did not have time. Next time :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf_clf.predict(test_samples.values)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['trip_duration'] = np.exp(predictions) - 1\n",
    "test['id']=Id\n",
    "test[['id', 'trip_duration']].to_csv('poonam.csv.gz', index=False, compression='gzip')\n",
    "test['trip_duration'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
